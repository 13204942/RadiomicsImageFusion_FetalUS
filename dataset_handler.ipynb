{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-CNN Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.one_d_cnn import *\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f396ea4a750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.custom_dataset import RadiomicDataset\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_hc18 = '/mnt/storage/fangyijie/HC18/radiomics'\n",
    "root_sp = '/mnt/storage/fangyijie/SP_transthalamic/radiomics'\n",
    "\n",
    "hc18_ga_csv = 'training_set_pixel_size_and_HC_GA.csv'\n",
    "sp_ga_csv = 'transthalamic_ga.csv'\n",
    "\n",
    "csv = 'features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc18\n",
    "raw_hc18_rad_df = pd.read_csv(os.path.join(root_hc18, csv))\n",
    "raw_hc18_ga_df = pd.read_csv(os.path.join(root_hc18, hc18_ga_csv))\n",
    "\n",
    "# spainish thalamic\n",
    "raw_sp_rad_df = pd.read_csv(os.path.join(root_sp, csv))\n",
    "raw_sp_ga_df = pd.read_csv(os.path.join(root_sp, sp_ga_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(997, 5)\n",
      "(1552, 3)\n"
     ]
    }
   ],
   "source": [
    "print(raw_hc18_ga_df.shape)\n",
    "print(raw_sp_ga_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'pixel size(mm)', 'head circumference (mm)', 'Unnamed: 3',\n",
      "       'GA'],\n",
      "      dtype='object')\n",
      "Index(['Name', 'HC_mm', 'GA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(raw_hc18_ga_df.columns)\n",
    "print(raw_sp_ga_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting GA\n",
    "# raw_hc18_ga_df = raw_hc18_ga_df.loc[:, ['filename', 'GA']].rename(columns={\"filename\": \"image_name\"})\n",
    "# raw_sp_ga_df = raw_sp_ga_df.loc[:, ['Name', 'GA']].rename(columns={\"Name\": \"image_name\"})\n",
    "\n",
    "# Predicting HC\n",
    "raw_hc18_ga_df = raw_hc18_ga_df.loc[:, ['filename', 'head circumference (mm)']].rename(columns={\"filename\": \"image_name\"})\n",
    "raw_sp_ga_df = raw_sp_ga_df.loc[:, ['Name', 'HC_mm']].rename(columns={\"Name\": \"image_name\"})\n",
    "raw_hc18_ga_df = raw_hc18_ga_df.rename(columns={\"head circumference (mm)\": \"HC\"})\n",
    "raw_sp_ga_df = raw_sp_ga_df.rename(columns={\"HC_mm\": \"HC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_hc_df = pd.merge(raw_hc18_rad_df, raw_hc18_ga_df, on=\"image_name\")\n",
    "src_sp_df = pd.merge(raw_sp_rad_df, raw_sp_ga_df, on=\"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(997, 120)\n",
      "(1552, 120)\n"
     ]
    }
   ],
   "source": [
    "print(src_hc_df.shape)\n",
    "print(src_sp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     79.86\n",
       "1    269.80\n",
       "2    174.76\n",
       "3    224.70\n",
       "4     71.91\n",
       "Name: HC, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_hc_df.iloc[:, -1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the first 22 columns\n",
    "X_hc18 = src_hc_df.iloc[:, 23:-1]\n",
    "y_hc18 = src_hc_df.iloc[:, -1]\n",
    "\n",
    "X_sp = src_sp_df.iloc[:, 23:-1]\n",
    "y_sp = src_sp_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 70% for training and 30% for testing\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_hc18, y_hc18, train_size=0.7)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_sp, y_sp, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X1_train, X2_train])\n",
    "y_train = pd.concat([y1_train, y2_train])\n",
    "\n",
    "X_test = pd.concat([X1_test, X2_test])\n",
    "y_test = pd.concat([y1_test, y2_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dataframe size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1783, 96)\n",
      "(1783,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 96)\n",
      "(766,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trg_dir = '/mnt/storage/fangyijie/radiomics_ga/ga_data'\n",
    "trg_dir = '/mnt/storage/fangyijie/radiomics_ga/hc_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(os.path.join(trg_dir, 'X_train.pkl'))\n",
    "y_train.to_pickle(os.path.join(trg_dir, 'y_train.pkl'))\n",
    "\n",
    "X_test.to_pickle(os.path.join(trg_dir, 'X_test.pkl'))\n",
    "y_test.to_pickle(os.path.join(trg_dir, 'y_test.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How load dataframe file (pkl)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_pickle(os.path.join(trg_dir, 'X_train.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "mamba"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
